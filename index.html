<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="WebMMU: A Multimodal, Multilingual Benchmark for Website Understanding & Code Generation">
  <meta name="keywords" content="WebMMU, AI, Machine Learning, Website Understanding, Code Generation, Benchmark, Multimodal, Multilingual">
  <meta name="author" content="WebMMU Research Team">
  <title>WebMMU: Multimodal Multilingual Website Understanding & Code Generation</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <!-- Navigation -->
  <nav class="navbar">
    <div class="container">
      <div class="navbar-content">
        <a href="#" class="navbar-brand">WebMMU</a>
        <ul class="navbar-menu">
          <li><a href="#about" class="navbar-item">About</a></li>
          <li><a href="#tasks" class="navbar-item">Tasks</a></li>
          <li><a href="#dataset" class="navbar-item">Dataset</a></li>
          <li><a href="#explore" class="navbar-item">Explore</a></li>
          <li><a href="#results" class="navbar-item">Results</a></li>
          <li><a href="assets/WebMMU_2025.pdf" target="_blank" class="navbar-btn">Paper</a></li>
        </ul>
      </div>
    </div>
  </nav>

  <!-- Hero Section -->
  <section class="hero">
    <div class="container">
      <h1 class="hero-title">WebMMU: A Multimodal, Multilingual Benchmark for Website Understanding & Code Generation</h1>
      <div class="hero-authors" style="justify-content:center;flex-wrap:wrap;gap:0.5rem 1.2rem;">
        <span class="author-chip"><a href="https://rabiul.me" target="_blank">Rabiul Awal</a><sup>1,2,‚úâ</sup></span>
        <span class="author-chip">Mahsa Massoud<sup>2</sup></span>
        <span class="author-chip">Zichao Li<sup>2</sup></span>
        <span class="author-chip">Aarash Feizi<sup>2</sup></span>
        <span class="author-chip">Suyuchen Wang<sup>2</sup></span>
        <span class="author-chip">Christopher Pal<sup>2,3</sup></span>
        <span class="author-chip">Aishwarya Agrawal<sup>2,4</sup></span>
        <span class="author-chip">David Vazquez<sup>2,5</sup></span>
        <span class="author-chip">Siva Reddy<sup>1,2</sup></span>
        <span class="author-chip">Juan A. Rodriguez<sup>2,6</sup></span>
        <span class="author-chip">Perouz Taslakian<sup>2,7</sup></span>
        <span class="author-chip">Spandana Gella<sup>2,8</sup></span>
        <span class="author-chip">Sai Rajeswar<sup>2</sup></span>
      </div>
      <div class="hero-affiliations" style="text-align:center;font-size:0.98rem;color:#64748b;margin:0.7rem 0 1.5rem 0;">
        <span><sup>1</sup>McGill University</span> &nbsp; 
        <span><sup>2</sup>Mila Quebec</span> &nbsp; 
        <span><sup>3</sup>Polytechnique Montr√©al</span> &nbsp; 
        <span><sup>4</sup>University of Montreal</span> &nbsp; 
        <span><sup>5</sup>Computer Vision Center, Barcelona</span> &nbsp; 
        <span><sup>6</sup>Universidad de los Andes</span> &nbsp; 
        <span><sup>7</sup>American University of Beirut</span> &nbsp; 
        <span><sup>8</sup>Microsoft Research</span> &nbsp; 
        <span><sup>‚úâ</sup><a href="mailto:rabiul.awal@mila.quebec">Contact</a></span>
      </div>
      <div class="hero-buttons">
        <a href="assets/WebMMU_2025.pdf" target="_blank" class="hero-btn">üìÑ Paper</a>
        <a href="https://github.com/webmmu/webmmu" target="_blank" class="hero-btn secondary">üíª Code</a>
        <a href="#dataset" class="hero-btn secondary">üîç Dataset</a>
      </div>
    </div>
  </section>

  <!-- About Section -->
  <section id="about" class="section">
    <div class="container">
        <h2 class="section-title">About</h2>

      <p class="section-subtitle">
        Whether you're building smarter web agents or testing the limits of multimodal models, WebMMU is your go-to testbed.
      </p>
     
  
      <div class="card">
        <p style="font-size:1.15rem;line-height:1.7;margin-bottom:2.2rem;max-width:700px;margin-left:auto;margin-right:auto;">
          WebMMU is a large-scale, expert-annotated benchmark for evaluating AI models on real-world web understanding and code generation. It covers three core tasks‚ÄîWebQA, Code Editing, and Mockup2Code‚Äîacross four languages and 20+ website domains. Each example is crafted and quality-checked by professionals, ensuring challenging, diverse, and realistic scenarios. By focusing on atomic, visually-grounded tasks, WebMMU enables fine-grained diagnosis of model strengths and weaknesses in reasoning, grounding, and code manipulation.
        </p>
        <img src="assets/WebMMU - main.png" alt="WebMMU benchmark overview" class="image image-large" />
        
        <h3 class="card-title">Key Features</h3>
        <ul class="features-list">
          <li><strong>üåê Multilingual:</strong> English, Spanish, German, French, revealing 20‚Äì40 point performance drops across languages.</li>
          <li><strong>üß© Three Core Tasks:</strong> 
            <b>WebQA</b> (complex, visually-grounded questions), 
            <b>Mockup2Code</b> (hand-drawn to code), 
            <b>Code Editing</b> (novel, real-world code patching with functional verification).
          </li>
          <li><strong>üñ•Ô∏è Real-World Data:</strong> 20+ domains, 4,392+ examples, all expert-annotated and QA'd by 127 professionals.</li>
          <li><strong>üîç Fine-Grained Evaluation:</strong> LLM-as-Judge and human scoring (89‚Äì91% agreement), with breakdowns by reasoning, agentic action, and code correctness.</li>
        </ul>
      </div>
    </div>
    </section>



      <!-- Tasks Section -->
      <section id="tasks" class="section">
        <div class="container">
              <h2 class="section-title">Tasks</h2>
          
          <div class="task-grid">
            <div class="task-card">
                <h3>WebQA</h3>
                <p>
                  Answer complex, visually-grounded questions about real website screenshots. 
                  <br><em>Example:</em> "Which button should a user click to view their order history?" or "Sum the prices of all items in the shopping cart."
                  <br><b>Measures:</b> Reasoning, spatial grounding, and content understanding.
                </p>
                </div>
            
            <div class="task-card">
                <h3>Mockup2Code</h3>
                <p>
                  Translate hand-drawn or digital mockups‚Äîcreated by experts from real sites‚Äîinto functional HTML/CSS code.
                  <br><em>Example:</em> "Generate code for this login page sketch, preserving layout and style."
                  <br><b>Measures:</b> Visual fidelity, code quality, and layout hierarchy.
                </p>
                </div>
            
            <div class="task-card">
                <h3>Code Editing</h3>
                <p>
                  Edit real HTML/CSS/JS code based on user instructions, with functional verification. 
                  <br><em>Example:</em> "Add a dark mode toggle to the navbar and ensure all text remains readable."
                  <br><b>Novelty:</b> First benchmark to evaluate fine-grained, visually-grounded code edits at scale.
                  <br><b>Measures:</b> Correctness, functionality, and structure-preserving changes.
                </p>
            </div>
          </div>
              </div>
      </section>

    <!-- Dataset Section -->
  <section id="dataset" class="section">
    <div class="container">
        <h2 class="section-title">Dataset Overview</h2>
        <p class="section-subtitle">
          Each example in WebMMU is crafted by expert annotators, with a three-stage QA process involving 127 professionals. The dataset spans e-commerce, government, blogs, and more, ensuring broad coverage and realistic challenges. This focus on quality and diversity surfaces genuine model weaknesses that simpler, synthetic datasets miss.
        </p>
      
      <div class="card">
        <div class="table-container">
          <table class="table">
          <thead>
            <tr>
                <th>Task</th>
                <th>English</th>
                <th>Spanish</th>
                <th>German</th>
                <th>French</th>
                <th>Total</th>
            </tr>
          </thead>
          <tbody>
            <tr>
                <td><strong>Website Images</strong></td>
              <td>392</td>
              <td>133</td>
              <td>130</td>
              <td>131</td>
              <td><strong>786</strong></td>
            </tr>
            <tr>
                <td><strong>WebQA</strong></td>
              <td>1,476</td>
              <td>484</td>
              <td>379</td>
              <td>456</td>
              <td><strong>2,795</strong></td>
            </tr>
            <tr>
                <td><strong>Mockup2Code</strong></td>
              <td>180</td>
              <td>93</td>
              <td>85</td>
              <td>78</td>
              <td><strong>436</strong></td>
            </tr>
            <tr>
                <td><strong>Code Editing</strong></td>
              <td>165</td>
              <td>75</td>
              <td>67</td>
              <td>68</td>
              <td><strong>375</strong></td>
            </tr>
            <tr>
                <td><strong>Total</strong></td>
              <td><strong>2,213</strong></td>
              <td><strong>785</strong></td>
              <td><strong>661</strong></td>
              <td><strong>733</strong></td>
              <td><strong>4,392</strong></td>
            </tr>
          </tbody>
        </table>
      </div>
      </div>
    </div>
  </section>


  <!-- Dataset Exploration Section -->
  <section id="explore" class="section">
    <div class="container">
      <h2 class="section-title">Explore Dataset</h2>
      <p class="section-subtitle">
        Browse through real samples from each task to understand the diversity and complexity of the WebMMU benchmark.
      </p>
      
      <div class="explore-tabs">
        <button class="explore-tab active" data-task="webqa">WebQA Samples</button>
        <button class="explore-tab" data-task="mockup2code">Mockup2Code Samples</button>
        <button class="explore-tab" data-task="codeedit">Code Editing Samples</button>
      </div>

      <div class="explore-content active" id="webqa-samples">
        <div class="sample-carousel">
          <button class="carousel-btn prev" data-task="webqa">‚Äπ</button>
          <div class="carousel-track" data-task="webqa">
            <!-- WebQA samples will be loaded here -->
          </div>
          <button class="carousel-btn next" data-task="webqa">‚Ä∫</button>
        </div>
        </div>

      <div class="explore-content" id="mockup2code-samples">
        <div class="sample-carousel">
          <button class="carousel-btn prev" data-task="mockup2code">‚Äπ</button>
          <div class="carousel-track" data-task="mockup2code">
            <!-- Mockup2Code samples will be loaded here -->
          </div>
          <button class="carousel-btn next" data-task="mockup2code">‚Ä∫</button>
        </div>
        </div>

      <div class="explore-content" id="codeedit-samples">
        <div class="sample-carousel">
          <button class="carousel-btn prev" data-task="codeedit">‚Äπ</button>
          <div class="carousel-track" data-task="codeedit">
            <!-- Code Editing samples will be loaded here -->
          </div>
          <button class="carousel-btn next" data-task="codeedit">‚Ä∫</button>
        </div>
      </div>
    </div>
  </section>

  <!-- Hugging Face Dataset Viewer Section -->
  <section id="hf-dataset" class="section">
    <div class="container">
      <h2 class="section-title">Explore Dataset on Hugging Face</h2>
      <h3 class="section-subtitle">Code Editing</h3>
      <iframe
        src="https://huggingface.co/datasets/McGill-NLP/WebMMU/embed/viewer/code_edit/english"
        frameborder="0"
        width="100%"
        height="560px"
        style="border-radius: 8px; background: #fff; box-shadow: 0 2px 8px rgba(0,0,0,0.04); margin-top: 1.5rem;"
        allowfullscreen
      ></iframe>
      <h3 class="section-subtitle" style="margin-top:2.5rem;">Mockup2Code</h3>
      <iframe
        src="https://huggingface.co/datasets/McGill-NLP/WebMMU/embed/viewer/mockup2code/English"
        frameborder="0"
        width="100%"
        height="560px"
        style="border-radius: 8px; background: #fff; box-shadow: 0 2px 8px rgba(0,0,0,0.04); margin-top: 1.5rem;"
        allowfullscreen
      ></iframe>
      <h3 class="section-subtitle" style="margin-top:2.5rem;">WebQA</h3>
      <iframe
        src="https://huggingface.co/datasets/McGill-NLP/WebMMU/embed/viewer/web_qa/english"
        frameborder="0"
        width="100%"
        height="560px"
        style="border-radius: 8px; background: #fff; box-shadow: 0 2px 8px rgba(0,0,0,0.04); margin-top: 1.5rem;"
        allowfullscreen
      ></iframe>
      </div>
    </section>

    <!-- Results Section -->
  <section id="results" class="section">
    <div class="container">
      <h2 class="section-title">Results & Key Insights</h2>
      <p style="font-size:1.08rem;line-height:1.7;margin-bottom:2.5rem;">
        WebMMU uses a rigorous evaluation protocol: LLM-as-Judge scoring, validated by human annotators (89‚Äì91% agreement), and automatic metrics (BLEU, TreeBLEU, visual similarity). This enables fine-grained analysis of model performance across reasoning, grounding, and code correctness. Notably, we find a strong correlation between VQA and code editing performance (r = 0.96), suggesting shared underlying skills.
      </p>
      <ul style="font-size:1.08rem;line-height:1.7;margin-bottom:2.5rem;">
        <li><b>Current AI models</b> (even the best) can extract basic info, but:
          <ul>
            <li>Struggle with complex reasoning, UI grounding, and code edits that actually work.</li>
            <li>Multilingual performance drops sharply outside English.</li>
          </ul>
        </li>
        <li><b>WebQA:</b> Most models <b>score below 50%</b> on reasoning; <b>agentic action</b> (UI navigation) is hardest (<b>&lt;10% accuracy</b>).</li>
        <li><b>Mockup2Code:</b> Proprietary models do well on simple layouts (score &gt;4/5), but <b>all models fail on complex/nested UIs</b>.</li>
        <li><b>Code Editing:</b> No model reliably produces correct, ready-to-use code edits‚Äî<b>manual fixes are still needed</b>.</li>
        <li><b>Why?</b> Models fail at spatial reasoning, multi-step logic, and precise UI element localization. Multilingual and cross-domain generalization remain major challenges.</li>
      </ul>
      <blockquote style="font-size:1.1rem;color:#334155;border-left:4px solid #3b82f6;padding-left:1.2rem;margin:1.5rem 0;">
        <b>Bottom line:</b> Even top models can't yet automate real-world web development.<br>
        <b>Future progress needs:</b> Better multimodal alignment, UI-aware modeling, and robust cross-lingual reasoning.
      </blockquote>

      <h3 class="section-title" style="margin-top:3rem;">Detailed Results</h3>
      <div class="tabs">
        <button class="tab active" data-tab="webqa">WebQA</button>
        <button class="tab" data-tab="mockup2code">Mockup2Code</button>
        <button class="tab" data-tab="codeedit">Code Editing</button>
      </div>
      <div class="tab-content active" id="webqa-content">
        <div class="card">
          <h3 class="card-title">Web VQA Performance</h3>
          <p class="results-summary">WebQA evaluates models on their ability to answer questions about real website screenshots across three categories: üß† Reasoning, ‚öôÔ∏è Agentic UI Actions, and üîé Content Understanding. Most models struggle with complex reasoning and agentic UI actions, especially outside English.</p>
          <p>Model accuracy (%) by question type and language. Best and runner-up models per size category are <strong>bold</strong> and <u>underlined</u>.</p>
          <div class="table-container">
            <table class="table">
            <thead>
              <tr>
                  <th rowspan="2">Model</th>
                  <th colspan="3">English</th>
                  <th colspan="3">French</th>
                  <th colspan="3">German</th>
                  <th colspan="3">Spanish</th>
              </tr>
              <tr>
                  <th>üß†</th>
                  <th>‚öôÔ∏è</th>
                  <th>üîé</th>
                  <th>üß†</th>
                  <th>‚öôÔ∏è</th>
                  <th>üîé</th>
                  <th>üß†</th>
                  <th>‚öôÔ∏è</th>
                  <th>üîé</th>
                  <th>üß†</th>
                  <th>‚öôÔ∏è</th>
                  <th>üîé</th>
              </tr>
            </thead>
            <tbody>
                <tr>
                  <td><strong>Claude3.5 Sonnet</strong></td>
                  <td><strong>51.4</strong></td>
                  <td><strong>3.7</strong></td>
                  <td><strong>64.1</strong></td>
                  <td><strong>53.0</strong></td>
                  <td><strong>12.7</strong></td>
                  <td>51.2</td>
                  <td><strong>26.9</strong></td>
                  <td><strong>15.6</strong></td>
                  <td><strong>31.6</strong></td>
                  <td><strong>63.8</strong></td>
                  <td><strong>15.9</strong></td>
                  <td><strong>41.9</strong></td>
              </tr>
                <tr>
                  <td>Gemini2.0 Flash</td>
                  <td>44.3</td>
                  <td>1.2</td>
                  <td>59.2</td>
                  <td>41.6</td>
                  <td>9.0</td>
                  <td><strong>52.8</strong></td>
                  <td>18.2</td>
                  <td>12.8</td>
                  <td>29.1</td>
                  <td>46.1</td>
                  <td>12.0</td>
                  <td>36.1</td>
              </tr>
                <tr>
                  <td><u>QwenVLSeventyTwoB</u></td>
                  <td><u>23.6</u></td>
                  <td><u>4.3</u></td>
                  <td>53.7</td>
                  <td><u>16.9</u></td>
                  <td><u>13.9</u></td>
                  <td>54.5</td>
                  <td><u>15.3</u></td>
                  <td><u>17.5</u></td>
                  <td>36.2</td>
                  <td><u>29.1</u></td>
                  <td><u>12.7</u></td>
                  <td>41.0</td>
              </tr>
            </tbody>
          </table>
        </div>
        </div>
      </div>
      <div class="tab-content" id="mockup2code-content">
        <div class="card">
          <h3 class="card-title">Mockup2Code Results</h3>
          <p class="results-summary">Mockup2Code evaluates how well models can generate HTML/CSS code from hand-drawn or digital web mockups. Models are scored on a 1-5 scale for both visual similarity and code quality. While proprietary models perform well on simple layouts, all models struggle with complex or deeply nested UI structures.</p>
          <img src="assets/mockup2sketch_results.png" alt="Mockup2Code performance results" class="image image-large" />
        </div>
      </div>
      <div class="tab-content" id="codeedit-content">
        <div class="card">
          <h3 class="card-title">Code Editing Results</h3>
          <p class="results-summary">Code Editing tests whether models can make precise, functional changes to real website code based on user instructions. Models are evaluated on correctness and functionality of their code modifications. Despite advances, no model reliably produces correct, ready-to-use code edits‚Äîmanual fixes are still required for production use.</p>
          <img src="assets/code-edits-performance.png" alt="Code editing performance results" class="image image-large" />
        </div>
      </div>
      </div>
    </section>

    <!-- BibTeX Section -->
  <section class="section">
    <div class="container">
      <h2 class="section-title">Citation</h2>
      <div class="bibtex-block">
@inproceedings{awal2025webmmu,
  title={WebMMU: A benchmark for multimodal multilingual website understanding and code generation},
  author={Awal, Rabiul and Massoud, Mahsa and Li, Zichao and Feizi, Aarash and Wang, Suyuchen and Pal, Christopher and Agrawal, Aishwarya and Vazquez, David and Reddy, Siva and Rodriguez, Juan A and others},
  booktitle={ICLR 2025 Third Workshop on Deep Learning for Code},
  year={2025}
}
      </div>
    </div>
    </section>

  <!-- Footer -->
  <footer class="footer">
    <div class="container">
      <p>&copy; 2025 WebMMU Benchmark. All rights reserved.</p>
      <p>
        <a href="https://github.com/servicenow/webmmu" target="_blank">GitHub</a> ‚Ä¢ 
        <a href="mailto:rabiul.awal@mila.quebec">Contact</a> ‚Ä¢ 
        <a href="https://arxiv.org/abs/xxxx.xxxx" target="_blank">arXiv</a>
      </p>
    </div>
  </footer>

  <script src="script.js"></script>
</body>
</html>
