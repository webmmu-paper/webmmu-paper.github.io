<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="WebMMU: A Multimodal, Multilingual Benchmark for Website Understanding & Code Generation">
  <meta name="keywords" content="WebMMU, AI, Machine Learning, Website Understanding, Code Generation, Benchmark, Multimodal, Multilingual">
  <meta name="author" content="WebMMU Research Team">
  <title>WebMMU: Multimodal Multilingual Website Understanding & Code Generation</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <!-- Navigation -->
  <nav class="navbar">
    <div class="container">
      <div class="navbar-content">
        <a href="#" class="navbar-brand">WebMMU</a>
        <ul class="navbar-menu">
          <li><a href="#about" class="navbar-item">About</a></li>
          <li><a href="#tasks" class="navbar-item">Tasks</a></li>
          <li><a href="#dataset" class="navbar-item">Dataset</a></li>
          <li><a href="#explore" class="navbar-item">Explore</a></li>
          <li><a href="#results" class="navbar-item">Results</a></li>
        </ul>
      </div>
    </div>
  </nav>

  <!-- Hero Section -->
  <section class="hero hero-blend">
    <div class="floating-circle-1"></div>
    <div class="floating-circle-2"></div>
    <div class="floating-circle-3"></div>
    <div class="floating-square"></div>
    <div class="floating-triangle"></div>
    <div class="floating-diamond"></div>
    <div class="floating-symbols">● ○ ◇ □</div>
    <div class="floating-hexagon"></div>
    <div class="floating-star"></div>
    <div class="floating-oval"></div>
    <div class="floating-cross"></div>
    <div class="floating-wave"></div>
    <div class="floating-dots">•••</div>
    <div class="floating-arrow"></div>
    <div class="floating-pentagon"></div>
    <div class="container hero-flex">
      <div class="hero-left">
        <div class="hero-meta-badge-row">
          <div class="hero-meta">EMNLP 2025</div>
          <div class="hero-multilingual-badge">Spotlight at MAR workshop @ CVPR 2025</div>
          <div class="hero-multilingual-badge">🌐 First Multilingual Benchmark for Web Agents</div>
        </div>
        <h1 class="hero-title">
          WebMMU: A Multimodal, Multilingual Benchmark for Website Understanding & Code Generation
        </h1>
        <div class="hero-authors-compact">
          <span>Rabiul Awal<sup>🦄∗†</sup></span>
          <span>Mahsa Massoud<sup>🦄†</sup></span>
          <span>Aarash Feizi<sup>🦄‡</sup></span>
          <span>Zichao Li<sup>🦄‡</sup></span>
          <span>Suyuchen Wang<sup>🦄</sup></span>
          <span>Christopher Pal<sup>🌌</sup></span>
          <span>Aishwarya Agrawal<sup>🎓</sup></span>
          <span>David Vazquez<sup>🦄</sup></span>
          <span>Siva Reddy<sup>🦄</sup></span>
          <span>Juan A. Rodriguez<sup>🏢</sup></span>
          <span>Perouz Taslakian<sup>🦄</sup></span>
          <span>Spandana Gella<sup>🦄</sup></span>
          <span>Sai Rajeswar<sup>🦄</sup></span>
        </div>
        <div class="hero-affiliations-compact">
          <span><sup>🦄</sup>ServiceNow</span>
          <span><sup>🌌</sup>Mila</span>
          <span><sup>🎓</sup>Université de Montréal</span>
          <span><sup>🏫</sup>McGill University</span>
          <span><sup>🏢</sup>École de Technologie Supérieure (ETS)</span>
          <span><sup>🏗️</sup>Polytechnique Montréal</span>
        </div>
        
        <div class="hero-authorship-legend">
          <span><sup>†</sup>Equal contribution (first authors)</span>
          <span><sup>‡</sup>Equal contribution (second authors)</span>
        </div>
    
        <div class="hero-description">
          WebMMU is a comprehensive benchmark that evaluates AI models' ability to understand and interact with real websites. Unlike existing benchmarks that use synthetic or simplified data, WebMMU uses authentic website screenshots and real-world code, covering three critical tasks: answering complex questions about web interfaces, converting visual mockups into functional code, and making precise code edits. With 4,392+ examples across four languages and 20+ website domains, each carefully crafted by 127 professionals, WebMMU reveals genuine model limitations that simpler datasets miss. This benchmark is essential for developing AI systems that can truly understand and manipulate web content in real-world scenarios.
        </div>
        <div class="hero-buttons">
          <a href="https://arxiv.org/abs/2508.16763" class="hero-btn">📄 Paper</a>
          <a href="https://github.com/webmmu/webmmu" class="hero-btn">💻 Code</a>
          <a href="https://huggingface.co/collections/mair-lab/webmmu-686777551dc5d822264e36f2" class="hero-btn">📥 Dataset</a>
          <a href="https://www.youtube.com/watch?v=56bS02W0-Hk&t=1s" class="hero-btn">🎥 Video Talk</a>
        </div>
        <em>*Corresponding: <a href="mailto:rabiul.awal@mila.quebec">rabiul.awal at mila.quebec</a></em>

      </div>
      <div class="hero-right">
        <img src="assets/webmmu_cover.png" alt="WebMMU Cover" class="hero-cover-image" />
      </div>
      
    </div>
  </section>

  <!-- About Section -->
  <section id="about" class="section">
    <div class="container">
        <h2 class="section-title">About</h2>

      <p class="section-subtitle">
        WebMMU addresses a critical gap in AI evaluation: how well can models understand and manipulate real websites? Current benchmarks often use simplified or synthetic data, masking the true challenges of real-world web interaction.
      </p>
     
  
      <div class="card">
      <ul class="features-list">
        <li></li>As AI systems increasingly interact with web interfaces, from automated testing to web development assistance, we need benchmarks that reflect real-world complexity. WebMMU fills this gap by using real-world website screenshots, real HTML/CSS/JavaScript code, and professionally crafted scenarios that mirror actual use cases. By focusing on atomic, visually-grounded tasks, WebMMU enables fine-grained diagnosis of model strengths and weaknesses in reasoning, grounding, and code manipulation.</li>
      </ul>
        <img src="assets/WebMMU - main.png" alt="WebMMU benchmark overview" class="image image-large" />
        
        <h3 class="card-title">Key Features</h3>
        <ul class="features-list">
          <li><strong>📊 Data Sources:</strong> Sourced from FineWeb (CommonCrawl) and heuristics for everyday actions such as popular shopping, booking appointments, travel, review websites, etc.</li>
          <li><strong>🌐 Multilingual:</strong> English, Spanish, German, French, revealing 20–40 point performance drops across languages.</li>
          <li><strong>🧩 Three Core Tasks:</strong> 
            <b>WebQA</b> (complex, visually-grounded questions), 
            <b>Mockup2Code</b> (hand-drawn to code), 
            <b>Code Editing</b> (novel, real-world code patching with functional verification).
          </li>
          <li><strong>🖥️ Multi-panel Screenshots:</strong> Mimics browsing experience with multiple panels.</li>
          <li><strong>🖥️ Real-World Data:</strong> 20+ domains, 4,392+ examples, all expert-annotated and QA'd by 127 professionals.</li>
          <li><strong>🔍 Fine-Grained Evaluation:</strong> LLM-as-Judge and human scoring (89–91% agreement), with breakdowns by reasoning, agentic action, and code correctness.</li>
        </ul>
      </div>
    </div>
    </section>



      <!-- Tasks Section -->
      <section id="tasks" class="section">
        <div class="container">
              <h2 class="section-title">Tasks</h2>
              <p class="section-subtitle">
                WebMMU evaluates three fundamental capabilities that AI systems need for real-world web interaction. Each task targets specific skills that are essential for building intelligent web agents and development tools.
              </p>
          
          <div class="task-grid">
            <div class="task-card">
                <h3>WebQA</h3>
                <p>
                  Ability to understand and reason about website content and functionality through visual analysis.
                  <br><br><em>Example questions:</em> "Which button should a user click to view their order history?" or "Sum the prices of all items in the shopping cart."
                  <br><br><strong>Measures:</strong> Spatial reasoning, understanding UI hierarchy, and connecting visual elements to functionality.
                </p>
                </div>
            
            <div class="task-card">
                <h3>Mockup2Code</h3>
                <p>
                  Ability to translate visual designs into functional HTML/CSS code that accurately reproduces the intended layout and styling.
                  <br><br><em>Example:</em> "Generate code for this login page sketch, preserving layout and style."
                  <br><br><strong>Measures:</strong> Understanding design intent, maintaining visual fidelity, and producing clean, maintainable code.
                </p>
                </div>
            
            <div class="task-card">
                <h3>Code Editing</h3>
                <p>
                  Ability to make precise, functional modifications to existing website code based on user requirements.
                  <br><br><em>Example:</em> "Add a dark mode toggle to the navbar and ensure all text remains readable."
                  <br><br><strong>Measures:</strong> Understanding code structure, preserving functionality, and making targeted changes without unintended side effects.
                </p>
            </div>
          </div>
              </div>
      </section>

    <!-- Dataset Section -->
  <section id="dataset" class="section">
    <div class="container">
        <h2 class="section-title">Dataset Overview</h2>
        <p class="section-subtitle">
          WebMMU's dataset is built with rigorous quality standards to ensure it reflects real-world complexity. 
        </p>
      
      <div class="card">
        <h3 class="card-title">Data Collection & Quality Assurance</h3>
        <p style="font-size:1.1rem;line-height:1.6;margin-bottom:2rem;">
          Our dataset spans diverse real-world scenarios: e-commerce platforms, government websites, educational portals, news sites, and more. This broad coverage ensures that models are tested on the full spectrum of web interfaces they might encounter in practice.           Each example undergoes a three-stage quality assurance process involving 127 professionals.
          Each example is authored by expert annotators with domain knowledge, then reviewed by multiple professionals to ensure accuracy and relevance.
        </p>
        
        <div class="table-container">
          <table class="table">
          <thead>
            <tr>
                <th>Task</th>
                <th>English</th>
                <th>Spanish</th>
                <th>German</th>
                <th>French</th>
                <th>Total</th>
            </tr>
          </thead>
          <tbody>
            <tr>
                <td><strong>Website Images</strong></td>
              <td>392</td>
              <td>133</td>
              <td>130</td>
              <td>131</td>
              <td><strong>786</strong></td>
            </tr>
            <tr>
                <td><strong>WebQA</strong></td>
              <td>1,476</td>
              <td>484</td>
              <td>379</td>
              <td>456</td>
              <td><strong>2,795</strong></td>
            </tr>
            <tr>
                <td><strong>Mockup2Code</strong></td>
              <td>180</td>
              <td>93</td>
              <td>85</td>
              <td>78</td>
              <td><strong>436</strong></td>
            </tr>
            <tr>
                <td><strong>Code Editing</strong></td>
              <td>165</td>
              <td>75</td>
              <td>67</td>
              <td>68</td>
              <td><strong>375</strong></td>
            </tr>
            <tr>
                <td><strong>Total</strong></td>
              <td><strong>2,213</strong></td>
              <td><strong>785</strong></td>
              <td><strong>661</strong></td>
              <td><strong>733</strong></td>
              <td><strong>4,392</strong></td>
            </tr>
          </tbody>
        </table>
      </div>
      </div>
    </div>
  </section>


  <!-- Dataset Exploration Section -->
  <section id="explore" class="section">
    <div class="container">
      <h2 class="section-title">Explore Dataset</h2>
      <p class="section-subtitle">
        Browse through real samples from each task to understand the diversity and complexity of the WebMMU benchmark.
      </p>
      
      <div class="explore-tabs">
        <button class="explore-tab active" data-task="webqa">WebQA Samples</button>
        <button class="explore-tab" data-task="mockup2code">Mockup2Code Samples</button>
        <button class="explore-tab" data-task="codeedit">Code Editing Samples</button>
      </div>

      <div class="explore-content active" id="webqa-samples">
        <div class="sample-carousel">
          <button class="carousel-btn prev" data-task="webqa">‹</button>
          <div class="carousel-track" data-task="webqa">
            <!-- WebQA samples will be loaded here -->
          </div>
          <button class="carousel-btn next" data-task="webqa">›</button>
        </div>
        </div>

      <div class="explore-content" id="mockup2code-samples">
        <div class="sample-carousel">
          <button class="carousel-btn prev" data-task="mockup2code">‹</button>
          <div class="carousel-track" data-task="mockup2code">
            <!-- Mockup2Code samples will be loaded here -->
          </div>
          <button class="carousel-btn next" data-task="mockup2code">›</button>
        </div>
        </div>

      <div class="explore-content" id="codeedit-samples">
        <div class="sample-carousel">
          <button class="carousel-btn prev" data-task="codeedit">‹</button>
          <div class="carousel-track" data-task="codeedit">
            <!-- Code Editing samples will be loaded here -->
          </div>
          <button class="carousel-btn next" data-task="codeedit">›</button>
        </div>
      </div>
    </div>
  </section>

  <!-- Hugging Face Dataset Viewer Section -->
  <section id="hf-dataset" class="section">
    <div class="container">
      <h2 class="section-title">Explore Dataset on Hugging Face</h2>
      <p class="section-subtitle">
        Browse through real samples from each task directly on Hugging Face. Each dataset contains authentic examples with expert annotations and quality assurance.
      </p>
      
      <div class="tabs">
        <button class="tab active" data-tab="codeedit-hf">Code Editing</button>
        <button class="tab" data-tab="mockup2code-hf">Mockup2Code</button>
        <button class="tab" data-tab="webqa-hf">WebQA</button>
      </div>
      
      <div class="tab-content active" id="codeedit-hf-content">
        <div class="card">
          <h3 class="card-title">Code Editing Dataset</h3>
          <p style="font-size:1.1rem;line-height:1.6;margin-bottom:2rem;">
            Explore real-world code editing examples where models must make precise modifications to existing HTML/CSS/JavaScript code based on user instructions.
          </p>
          <iframe
            src="https://huggingface.co/datasets/McGill-NLP/WebMMU/embed/viewer/code_edit/english"
            frameborder="0"
            width="100%"
            height="560px"
            style="border-radius: 8px; background: #fff; box-shadow: 0 2px 8px rgba(0,0,0,0.04);"
            allowfullscreen
          ></iframe>
        </div>
      </div>
      
      <div class="tab-content" id="mockup2code-hf-content">
        <div class="card">
          <h3 class="card-title">Mockup2Code Dataset</h3>
          <p style="font-size:1.1rem;line-height:1.6;margin-bottom:2rem;">
            Browse hand-drawn and digital mockups that models must convert into functional HTML/CSS code, testing visual-to-code translation capabilities.
          </p>
          <iframe
            src="https://huggingface.co/datasets/McGill-NLP/WebMMU/embed/viewer/mockup2code/English"
            frameborder="0"
            width="100%"
            height="560px"
            style="border-radius: 8px; background: #fff; box-shadow: 0 2px 8px rgba(0,0,0,0.04);"
            allowfullscreen
          ></iframe>
        </div>
      </div>
      
      <div class="tab-content" id="webqa-hf-content">
        <div class="card">
          <h3 class="card-title">WebQA Dataset</h3>
          <p style="font-size:1.1rem;line-height:1.6;margin-bottom:2rem;">
            Explore complex, visually-grounded questions about real website screenshots, testing models' ability to understand and reason about web interfaces.
          </p>
          <iframe
            src="https://huggingface.co/datasets/McGill-NLP/WebMMU/embed/viewer/web_qa/english"
            frameborder="0"
            width="100%"
            height="560px"
            style="border-radius: 8px; background: #fff; box-shadow: 0 2px 8px rgba(0,0,0,0.04);"
            allowfullscreen
          ></iframe>
        </div>
      </div>
    </div>
  </section>

    <!-- Results Section -->
  <section id="results" class="section">
    <div class="container">
      <h2 class="section-title">Results & Key Insights</h2>
      <p class="section-subtitle">
        WebMMU's comprehensive evaluation reveals significant gaps in current AI capabilities for real-world web interaction. Our results provide actionable insights for researchers and developers working on multimodal AI systems.
      </p>
      
      <div class="card">        
      <h3 class="section-title" style="margin-top:3rem;">Detailed Results</h3>
      <p style="font-size:1.08rem;line-height:1.7;margin-bottom:2rem;">
        WebMMU uses a rigorous evaluation protocol combining LLM-as-Judge scoring (validated by human annotators with 89–91% agreement) and automatic metrics (BLEU, TreeBLEU, visual similarity). This multi-faceted approach enables fine-grained analysis of model performance across reasoning, grounding, and code correctness. 
      </p>
      <div class="tabs">
        <button class="tab active" data-tab="webqa">WebQA</button>
        <button class="tab" data-tab="mockup2code">Mockup2Code</button>
        <button class="tab" data-tab="codeedit">Code Editing</button>
      </div>
      <div class="tab-content active" id="webqa-content">
        <div class="card">
          <h3 class="card-title">Web VQA Performance</h3>
          <p class="results-summary">WebQA evaluates models on their ability to answer questions about real website screenshots across three categories: 🧠 Reasoning (complex logical thinking), ⚙️ Agentic UI Actions (navigation and interaction), and 🔎 Content Understanding (basic information extraction). Most models struggle with complex reasoning and agentic UI actions, especially outside English.</p>
          <p>Model accuracy (%) by question type and language. Best and runner-up models per size category are <strong>bold</strong> and <u>underlined</u>.</p>
          <div class="table-container">
            <table class="table">
            <thead>
              <tr>
                  <th rowspan="2">Model</th>
                  <th colspan="3">English</th>
                  <th colspan="3">French</th>
                  <th colspan="3">German</th>
                  <th colspan="3">Spanish</th>
              </tr>
              <tr>
                  <th>🧠</th>
                  <th>⚙️</th>
                  <th>🔎</th>
                  <th>🧠</th>
                  <th>⚙️</th>
                  <th>🔎</th>
                  <th>🧠</th>
                  <th>⚙️</th>
                  <th>🔎</th>
                  <th>🧠</th>
                  <th>⚙️</th>
                  <th>🔎</th>
              </tr>
            </thead>
            <tbody>
                <tr>
                  <td><strong>Claude3.5 Sonnet</strong></td>
                  <td><strong>51.4</strong></td>
                  <td><strong>3.7</strong></td>
                  <td><strong>64.1</strong></td>
                  <td><strong>53.0</strong></td>
                  <td><strong>12.7</strong></td>
                  <td>51.2</td>
                  <td><strong>26.9</strong></td>
                  <td><strong>15.6</strong></td>
                  <td><strong>31.6</strong></td>
                  <td><strong>63.8</strong></td>
                  <td><strong>15.9</strong></td>
                  <td><strong>41.9</strong></td>
              </tr>
                <tr>
                  <td>Gemini2.0 Flash</td>
                  <td>44.3</td>
                  <td>1.2</td>
                  <td>59.2</td>
                  <td>41.6</td>
                  <td>9.0</td>
                  <td><strong>52.8</strong></td>
                  <td>18.2</td>
                  <td>12.8</td>
                  <td>29.1</td>
                  <td>46.1</td>
                  <td>12.0</td>
                  <td>36.1</td>
              </tr>
                <tr>
                  <td><u>QwenVLSeventyTwoB</u></td>
                  <td><u>23.6</u></td>
                  <td><u>4.3</u></td>
                  <td>53.7</td>
                  <td><u>16.9</u></td>
                  <td><u>13.9</u></td>
                  <td>54.5</td>
                  <td><u>15.3</u></td>
                  <td><u>17.5</u></td>
                  <td>36.2</td>
                  <td><u>29.1</u></td>
                  <td><u>12.7</u></td>
                  <td>41.0</td>
              </tr>
            </tbody>
          </table>
        </div>
        </div>
      </div>
      <div class="tab-content" id="mockup2code-content">
        <div class="card">
          <h3 class="card-title">Mockup2Code Results</h3>
          <p class="results-summary">Mockup2Code evaluates how well models can generate HTML/CSS code from hand-drawn or digital web mockups. Models are scored on a 1-5 scale for both visual similarity (how well the generated code matches the visual design) and code quality (cleanliness, maintainability, and best practices). While proprietary models perform well on simple layouts, all models struggle with complex or deeply nested UI structures.</p>
          <img src="assets/mockup2sketch_results.png" alt="Mockup2Code performance results" class="image image-large" />
        </div>
      </div>
      <div class="tab-content" id="codeedit-content">
        <div class="card">
          <h3 class="card-title">Code Editing Results</h3>
          <p class="results-summary">Code Editing tests whether models can make precise, functional changes to real website code based on user instructions. Models are evaluated on correctness (does the code work as intended?) and functionality (does it preserve existing features?). Despite advances in code generation, no model reliably produces correct, ready-to-use code edits—manual fixes are still required for production use.</p>
          <img src="assets/code-edits-performance.png" alt="Code editing performance results" class="image image-large" />
        </div>
      </div>
      </div>

      <h3 class="card-title">Key Insights</h3>
      <div style="font-size:1.08rem;line-height:1.7;margin-bottom:2.5rem;">
        <p><strong>Grounding Is the Hardest, Reasoning Comes Next, General Understanding Is the Easiest</strong></p>
        <p>WebMMU shows a clear difficulty gap across tasks. Most models handle basic visual understanding (like reading labels and identifying images) fairly well. They do worse at multi-step reasoning, such as performing calculations or combining information from different parts of a web page. But the hardest challenge is grounding — identifying the exact location of elements on a page and reasoning about user actions (e.g., where to click). For example, while many models could list navigation categories correctly, few could pinpoint where to click to open the "About Us" page, with grounding accuracy often falling below 10%. This reflects a gap between recognizing content and understanding how users interact with it.</p>
        

        <p><strong>Simple Layouts Are Fine, But Complex UI Hierarchies Break the Models</strong></p>
        <p>When turning design mockups into HTML/CSS code, most models succeed on simple, flat layouts. But as soon as mockups include nested sections, multi-column layouts, or complex styling, the models break down. They often flatten the hierarchy, misalign elements, or miss relationships between components. For example, while they can correctly generate a basic "Contact Us" page, they struggle with a product page featuring sidebars, filters, and product grids. This suggests current models understand basic page layouts but lack deeper comprehension of modern, structured web design.</p>
        
        <p><strong>Code Editing: Models Generate Edits, But Risk Breaking the Site</strong></p>
        <p>In code editing tasks, models can follow instructions like "Add a header with search and post buttons," but often produce edits that break the site's structure or behavior. While the syntax of their HTML/CSS/JavaScript is mostly correct, they miss subtle dependencies, like class names or JavaScript functions, that keep the page functional. Even top models cannot yet generate reliable, ready-to-deploy code patches. This makes human review essential for all but the simplest edits.</p>
        
        <p><strong>Open-Source Models Lag Behind Closed-Source Models, Especially on Complex Tasks</strong></p>
        <p>Across all tasks, closed-source models like Gemini 2.0 Flash and Claude 3.5 consistently outperform open-source alternatives. They show better grounding, more accurate reasoning, and higher-quality code generation. For example, in the mockup-to-code task, closed-source models score above 4 out of 5 on simple layouts, while open-source models often struggle to score above 3. However, even the best models — closed or open — fail on complex designs, especially with nested layouts and precise spacing. Open-source models also suffer from greater multilingual performance drops, highlighting the training and resource gap between the two categories.</p>
        
        <p><strong>Multilingual Tasks Expose Major Gaps in Cross-Lingual Generalization</strong></p>
        <p>WebMMU covers English, Spanish, German, and French. Across all tasks, performance in non-English languages drops significantly — sometimes by more than half. Grounding and reasoning suffer most in these languages. This reveals that despite large training datasets, models haven't yet learned to generalize well to multilingual websites, which often have layout and content differences across languages.</p>
        
        <p><strong>The Big Picture: Real-World Web Automation Remains a Challenge</strong></p>
        <p>WebMMU shows that while AI models are progressing, they remain far from automating real-world web development. They can extract basic information and generate simple UI code, but they struggle with reasoning, structured code generation, precise edits, and multilingual scenarios. Closing this gap will require better multimodal reasoning, web-specific model architectures, and stronger cross-lingual capabilities — essential steps toward building truly intelligent web automation agents.</p>
      </div>

    </div>
    </section>



    <!-- BibTeX Section -->
  <section class="section">
    <div class="container">
      <h2 class="section-title">Citation</h2>
      <div class="bibtex-block">
@inproceedings{awal2025webmmu,
  title={WebMMU: A benchmark for multimodal multilingual website understanding and code generation},
  author={Awal, Rabiul and Massoud, Mahsa and Li, Zichao and Feizi, Aarash and Wang, Suyuchen and Pal, Christopher and Agrawal, Aishwarya and Vazquez, David and Reddy, Siva and Rodriguez, Juan A and others},
  booktitle={Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year={2025}
}
      </div>
    </div>
    </section>

  <!-- Footer -->
  <footer class="footer">
    <div class="container">
      <p>&copy; 2025 WebMMU Benchmark. All rights reserved.</p>
      <p>
        <a href="https://github.com/servicenow/webmmu" target="_blank">GitHub</a> • 
        <a href="mailto:rabiul.awal@mila.quebec">Contact</a> • 
        <a href="https://arxiv.org/abs/2508.16763" target="_blank">arXiv</a>
      </p>
    </div>
  </footer>

  <script src="script.js"></script>
</body>
</html>
